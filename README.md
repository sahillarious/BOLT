B.O.L.T â€“ Behavioral Object Locomotion & Tracking

B.O.L.T is a real-time vision-guided object tracking system for the Unitree Go2 quadruped robot. 
The system integrates a custom-trained YOLOv8 object detector, monocular depth estimation, and a state-based control architecture to autonomously detect, 
track, and follow objects with sub-50 ms latency on edge hardware.

![Unitree Go2 Robot](Unitree_GO2.png)

ðŸš€ Features
Real-time object detection using YOLOv8
Monocular depth-based distance estimation (Intel RealSense)
Closed-loop perception â†’ control pipeline
Finite State Machine (FSM) for smooth and safe locomotion
Dynamic target switching (green / pink / yellow ball)
Edge deployment optimized for Jetson Nano
Live MJPEG video streaming for monitoring

ðŸ§  System Overview
Camera â†’ Object Detection â†’ Depth Estimation â†’ FSM Control â†’ Velocity Commands â†’ Robot Motion
The system continuously updates motion commands based on the latest visual feedback, enabling responsive and stable autonomous tracking without relying on SLAM.

ðŸ—ï¸ Architecture
Hardware
1. Unitree Go2 Quadruped
2. Intel RealSense RGB-D Camera
3. NVIDIA Jetson Nano

Software
1. Python
2. YOLOv8 (Ultralytics)
3. OpenCV
4. ROS / ROS2 (for robot communication)

ðŸ“Š Performance
1. Average latency: ~48 ms
2. Worst-case latency: ~61 ms
3. Detection accuracy: mAP@0.5 â‰ˆ 0.995
4. Tracking success rate: >90% (indoor environments)
5. Robustness: Works across varied lighting conditions

ðŸ‘¥ Authors
Sahil Sawant - sahilshi@buffalo.edu
Atharva Prabhu - aprabhu5@buffalo.edu

EAS 563 â€“ AI Capstone
University at Buffalo
Advisor: Prof. David Doermann
